{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOXhOwGNyq5DC/c+iCpLPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schauppi/Udemy_TensorFlow_Developer/blob/main/Abschnitt_8_NLP_fundamentals_in_TensorFlow/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brfcRn4FYSEI"
      },
      "source": [
        "# Introduction to NLP Fundamentals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (text or speech sequences).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QWG6CLQYl2q"
      },
      "source": [
        "## check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_qTL4EDYkQJ",
        "outputId": "5cad0e30-7914-48da-f8a0-49a566aa0628"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-512cf063-0d99-6e34-fcc5-9177b964bd20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aZmZtEoYzYC"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrI9HOIsYoRn",
        "outputId": "b220375e-2b5f-40e0-bbab-48eafed85ee5"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-13 09:01:51--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-13 09:01:52 (60.6 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaoUj_eEY7Qd"
      },
      "source": [
        "# Import series of helper functions\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA3BANtyZOfZ"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we´re going to be using is Kaggle´s introduction to BLP dataset (text samples of Tweets labelled as disaster or nor disaster)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8enYkfd3ZKRF",
        "outputId": "ab80a06b-0a69-4043-dfc7-c67a92a408fd"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-13 09:01:52--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 74.125.204.128, 64.233.189.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip.1’\n",
            "\n",
            "\r          nlp_getti   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-08-13 09:01:52 (103 MB/s) - ‘nlp_getting_started.zip.1’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NepIUlgTaTjG"
      },
      "source": [
        "## Visualizing a text dataset \n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python.\n",
        "\n",
        "Another way to do this is to use pandas..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "iKlNw6UTZwDi",
        "outputId": "a7a22ab4-4db2-4a3d-f793-8323349d92ad"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hM-X0YRjbLiG",
        "outputId": "01513ef3-2c99-457d-e1ff-142551583fa8"
      },
      "source": [
        "train_df[\"text\"][0]"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "2X6XBmB_bT1A",
        "outputId": "e27ac10c-a110-4cbd-e62e-aa371a98e6cd"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "MMs6Thd1brIx",
        "outputId": "62725bd3-e536-4d08-90e0-9f7c994d28b2"
      },
      "source": [
        "#What does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQvs7BH1b0HR",
        "outputId": "0bfb068f-13c6-4e45-895b-583a1b684945"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBckr71Sb-RY",
        "outputId": "abc2dc03-9fc0-456e-94aa-3a677b885441"
      },
      "source": [
        "# How many total samples\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjOLQo-ccfPP",
        "outputId": "080a1b53-57c6-4c01-cf8b-b5d11c9129f9"
      },
      "source": [
        "# Let´s visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) #create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "RT @tonyhsieh: 'The person who dances with you in the rain will most likely walk with you in the storm.' -Anonymous\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Beyonce Is my pick for http://t.co/nnMQlz91o9 Fan Army #Beyhive http://t.co/o91f3cYy0R 77\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Ted Cruz fires back at Jeb &amp; Bush: ÛÏWe lose because of Republicans like Jeb &amp; Mitt.Û [Video] -  http://t.co/BFTHaHLCr0\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "An IS group suicide bomber detonated an explosives-packed vest in a mosque inside a Saudi special forces headquarters killing 15 people.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Top link: Reddit's new content policy goes into effect many horrible subreddits banned or quarantined http://t.co/zCp5cszSLl\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN1kmH1lebDU"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cGP7JrtdiFG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Use train_test_split to split train data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA52UYsYfI6O",
        "outputId": "cd72c59f-8105-4ce1-bbe0-4e2b785176e5"
      },
      "source": [
        "#Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NYv_XABfaTB",
        "outputId": "a6a99d9b-753d-4545-b9f4-d89b49f0ffbc"
      },
      "source": [
        "#Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI_lt4Toha-E"
      },
      "source": [
        "## Convert text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you´ll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways you can to this, namely:\n",
        "* Tokenization - direct mapping of token (a token could be a word or character to number)\n",
        "* Embedding - create a matrix of a feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao-SoEImxQkT"
      },
      "source": [
        "## Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gswSUX3fkia"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, #how man word in the vocabulary (automatically adds <OOV>)\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None, #create groups of n-words\n",
        "                                    output_mode=\"int\", #how to map tokens to numbers\n",
        "                                    output_sequence_length=None, #how long the sequences should be\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJUThofr1zTD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62cb2db6-0e96-4b33-ba2c-e891c0fc081a"
      },
      "source": [
        "train_sentences[0].split()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WgssXeE15HI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76ac013-0fe0-41ed-d469-a7833ee5d23a"
      },
      "source": [
        "len(train_sentences[0].split())"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hndkqiayxaWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c6dc15-e331-432a-c94d-39edf9c5e178"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S0U1Vs81_uk"
      },
      "source": [
        "#Setup vectorizeation variables\n",
        "max_vocab_length = 10000 #max number of words to have in our vocabulary\n",
        "max_length = 15 #max length our sequences will be (e.g. how many words from a tweet will our model see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7hZt2gI2w3P"
      },
      "source": [
        "#Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb-LpWWe4eZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf90b161-f0d5-4f12-ec8a-a41f9869ce92"
      },
      "source": [
        "#Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There´s a flood in my street\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  1,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHfr_FJ94qE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "090c4d83-3710-4e17-ae20-3fd3f9293ea7"
      },
      "source": [
        "# choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence} \\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " Hellfire! We donÛªt even want to think about it or mention it so letÛªs not do anything that leads to it!       \n",
            "\n",
            "Vectorized version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 546,   46, 1029,  151,  138,    5,  125,   54,   15,   53, 1636,\n",
              "          15,   28, 2405,   34]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3erFgIRi5U-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "915d2c2f-a475-4097-9bec-a0b3ead76fa9"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] #get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] #get the least common words\n",
        "print(len(words_in_vocab)) \n",
        "print(top_5_words)\n",
        "print(bottom_5_words)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "['', '[UNK]', 'the', 'a', 'in']\n",
            "['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpm-ipVZ9sW3"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we´re going to use TensorFlow´s embedding layer.\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* input_dim = the size of the vocabulary\n",
        "* output_dim = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* input_length = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c5MNROG5ydx"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             input_length=max_length)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4516W7r-4Z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec599e1-a7ef-41cf-ff69-0d0b161eaaac"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text: \\n {random_sentence} \\\n",
        "      \\n\\nEmbedded version\")\n",
        "#Embed the random sentence\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text: \n",
            " I always tell my mom to bring me food or I will hold her cat hostage??       \n",
            "\n",
            "Embedded version\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.03761773, -0.0112257 ,  0.01476211, ..., -0.03036818,\n",
              "          0.04098736,  0.03273804],\n",
              "        [-0.02420437,  0.04045621, -0.01493071, ..., -0.02203947,\n",
              "          0.03672654, -0.03010169],\n",
              "        [-0.01374195,  0.03537961,  0.04202158, ...,  0.03439074,\n",
              "          0.02029295, -0.01105816],\n",
              "        ...,\n",
              "        [-0.02919639,  0.00490249, -0.03459734, ..., -0.0243655 ,\n",
              "          0.02161661, -0.01974881],\n",
              "        [-0.00856047,  0.02351776, -0.02034231, ...,  0.0078366 ,\n",
              "         -0.023106  ,  0.01324241],\n",
              "        [ 0.0218753 , -0.01850209,  0.00225643, ..., -0.02669281,\n",
              "          0.01481762, -0.01648034]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0hDipEc_fF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3857d201-bbdb-475c-8c95-5e409682c895"
      },
      "source": [
        "# Check out a single token´s embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-3.7617732e-02, -1.1225700e-02,  1.4762115e-02,  5.3932294e-03,\n",
              "         3.7346710e-02,  7.0132315e-05,  3.8266990e-02, -4.7331896e-02,\n",
              "        -1.1163391e-02,  3.5320017e-02, -3.1987384e-02,  1.2967970e-02,\n",
              "         4.6969976e-02,  2.2026148e-02,  2.3454536e-02,  1.3531137e-02,\n",
              "        -3.3764161e-02,  9.9448077e-03, -4.8340667e-02, -2.2862589e-02,\n",
              "        -2.6580466e-02,  2.2990596e-02,  3.0739341e-02,  2.9189233e-02,\n",
              "         2.4188582e-02, -4.1666280e-02,  3.6154632e-02, -2.4772063e-03,\n",
              "         2.3927581e-02,  9.3980879e-04, -1.2301318e-03, -9.2371553e-04,\n",
              "         8.0453642e-03, -2.2423780e-02, -4.4842400e-02,  3.0274902e-02,\n",
              "        -3.5245251e-02,  2.7101945e-02, -3.8912356e-02,  3.5576154e-02,\n",
              "        -1.9722974e-02,  1.0623656e-02, -2.1076132e-02, -1.8671285e-02,\n",
              "         1.7127339e-02,  4.5612719e-02, -4.3930557e-02, -2.0642638e-02,\n",
              "        -2.2073878e-02, -2.7460564e-02, -8.2296133e-03,  1.9185830e-02,\n",
              "         5.8315694e-05,  2.8252602e-05, -2.0898152e-02, -1.5989326e-02,\n",
              "         3.8303062e-04,  1.4130641e-02,  2.3809079e-02, -4.8078217e-02,\n",
              "        -4.8360229e-03,  2.2742376e-03, -2.8231932e-02, -2.6629940e-03,\n",
              "        -4.7107115e-03,  2.5340233e-02,  1.4824159e-03, -4.6621811e-02,\n",
              "         1.7089937e-02, -1.1970699e-02, -3.6474489e-02, -4.9783587e-03,\n",
              "        -4.7343314e-02,  2.4556089e-02, -4.1701782e-02, -3.0549480e-02,\n",
              "         1.0876764e-02,  1.3000939e-02,  4.6775904e-02,  3.7346292e-02,\n",
              "        -4.1185953e-02,  2.8518569e-02, -5.0253980e-03,  3.5964202e-02,\n",
              "        -4.4700492e-02,  4.0597845e-02, -4.2765703e-02, -6.8991557e-03,\n",
              "        -3.4334421e-02,  1.1609681e-03,  2.5709417e-02,  1.1586271e-02,\n",
              "        -3.0424111e-03, -4.0909052e-03, -1.4106762e-02, -4.0011048e-02,\n",
              "        -1.3457645e-02,  1.0429431e-02, -3.8181830e-02,  3.9498631e-02,\n",
              "         3.8836408e-02, -2.7585352e-02, -1.3074391e-03, -3.3918753e-02,\n",
              "         2.9485766e-02, -1.9861519e-02,  1.4526475e-02, -3.7670217e-02,\n",
              "         3.9955590e-02,  2.8973091e-02,  1.5409682e-02, -3.0894209e-02,\n",
              "        -1.4841091e-02, -4.3233085e-02,  2.7105808e-03,  4.9560439e-02,\n",
              "         4.2881135e-02,  2.7730945e-02, -2.3664463e-02, -3.5293818e-02,\n",
              "        -4.4700634e-02,  8.2337037e-03,  3.4412574e-02,  3.6447216e-02,\n",
              "         4.3562923e-02, -3.0368185e-02,  4.0987361e-02,  3.2738041e-02],\n",
              "       dtype=float32)>, TensorShape([128]), 'I')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_717Ykw3pcB"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we´ve got a way to turn our text sequences into numbers, it´s time to start building a series of modelling experiments.\n",
        "\n",
        "We´ll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM\n",
        "* Model 3: GRU\n",
        "* Model 4: Bidirectional LSTM\n",
        "* Model 5: 1D Convolution NN\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "How are we goint to approach all of these?\n",
        "\n",
        "Use the standard steps in modelling with tensorflow:\n",
        "\n",
        "* Create a model\n",
        "* Build a model\n",
        "* Fit the model\n",
        "* Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygq79xTj6M1f"
      },
      "source": [
        "### Model 0: Getting a baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vg9S-EeAHPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ec4b7f-8b4e-4046-c3e0-7756984d1722"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#Create tokenization and modellin pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), #cobvert words to numbers\n",
        "                    (\"clf\", MultinomialNB()) #model the text\n",
        "])\n",
        "\n",
        "#Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83nEZIMI6tgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724cbb76-8e80-4fa4-8eca-38bb75dedf59"
      },
      "source": [
        "# Evaluate the baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiJScoWE7iU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9666a75-a251-45e5-8e3f-222cfccf97f3"
      },
      "source": [
        "#Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoHruQ_V87Vj"
      },
      "source": [
        "### Creating an evaluation function for our model experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuQY5oAX8HA_"
      },
      "source": [
        "#Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 scroe of a binary classification model.\n",
        "  \"\"\"\n",
        "  #Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  #Calculate model precision, racall and f1-scroe using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "\n",
        "  return model_results"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eGZRZvBSKSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8349a04c-2fb5-4dbf-d832-f7dab0d2d45f"
      },
      "source": [
        "#Get baseline results\n",
        "baseline_results = calculate_results(val_labels, baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvTt6dV_TAVM"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gplFfgRUSSz3"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VvIIE1QTqQw"
      },
      "source": [
        "# Build model with Functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) #inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) #turn the input text into numbers\n",
        "x = embedding(x) #create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) #create the feature vector for each token\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) #Create the binary output\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymdheYnHVTq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a79ebd-fc1b-42fc-bc36-3d07318a7d86"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_3 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMHE2ZokVWHR"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntITdiQTV30D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08564012-43f1-4afd-a615-253eafb55fa7"
      },
      "source": [
        "#Fit the model\n",
        "model_1_history = model_1.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_1_dense\")])"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210813-090156\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 20ms/step - loss: 0.6124 - accuracy: 0.6987 - val_loss: 0.5372 - val_accuracy: 0.7585\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.4409 - accuracy: 0.8200 - val_loss: 0.4690 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.3459 - accuracy: 0.8597 - val_loss: 0.4614 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.2835 - accuracy: 0.8902 - val_loss: 0.4647 - val_accuracy: 0.7874\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.2368 - accuracy: 0.9132 - val_loss: 0.4771 - val_accuracy: 0.7808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4-NNvD2WUgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e516a43c-27e1-4758-aea1-8b966d31e3f7"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47708848118782043, 0.7808399200439453]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZHhgscQWmDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a94bea-9538-4eda-88bb-0b57e81a1c90"
      },
      "source": [
        "#Make some predictions and evaluate those\n",
        "model_1_preds_probs = model_1.predict(val_sentences)\n",
        "model_1_preds_probs.shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ1dKi-VWviQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8a43b7-305f-47df-bddf-acb9e4ac1acd"
      },
      "source": [
        "#look at a single prediction\n",
        "model_1_preds_probs[0]"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4013793], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slIc8zCuW1gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f852b717-222f-4ec3-bef4-86f56c00b5b7"
      },
      "source": [
        "#look at the first 10 predictions\n",
        "model_1_preds_probs[:10]"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4013793 ],\n",
              "       [0.74617606],\n",
              "       [0.9976446 ],\n",
              "       [0.1371503 ],\n",
              "       [0.10724574],\n",
              "       [0.93752396],\n",
              "       [0.91679657],\n",
              "       [0.99386567],\n",
              "       [0.9741527 ],\n",
              "       [0.2912919 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KikJLnt4YnWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857a2f17-fe7a-425e-a9cd-6c591a7771d9"
      },
      "source": [
        "#Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_preds_probs))\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gVyMlGSY7I9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2436c5b-a7ec-4a82-b354-0f2ded37a62f"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(val_labels, model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'f1': 0.7783998521836788,\n",
              " 'precision': 0.783783808499639,\n",
              " 'recall': 0.7808398950131233}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3NRWql9ZGL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5a6a08-f4e0-4e98-c607-46807671f12c"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcumLC6PahI1"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1HPxXUkZG2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28681bb-ee29-4dfa-b397-15779e3172c3"
      },
      "source": [
        "# Get the vocabulary from the text vectorization\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2QbJUbibBoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7cfbd5-918b-4172-d3a1-68f1c7585e06"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_3 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4A7qoLAbITK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ca2d48-9e33-45bb-b4ee-9f64c9218839"
      },
      "source": [
        "#Get weight matrix of embedding layer\n",
        "#these are the numerical representations of each token in our training data\n",
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape) #same size as vocav size and embedding dim"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UXvNB4scMwM"
      },
      "source": [
        "To visualize, TensorFlow has a handy tool calles projector : https://projector.tensorflow.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxWZ_vnKbkva"
      },
      "source": [
        "#Create embedding files\n",
        "\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vICo5w0hdI1v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81d5aee0-8e50-4724-9db0-eaf356efb9cf"
      },
      "source": [
        "#Download files from colab to upload to projector\n",
        "\"\"\"\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass\n",
        "\"\"\""
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntry:\\n  from google.colab import files\\n  files.download('vectors.tsv')\\n  files.download('metadata.tsv')\\nexcept Exception:\\n  pass\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcxxQYbGpZN8"
      },
      "source": [
        "## Recurrent Neural Networks (RNN´s)\n",
        "\n",
        "The premise of a RNN is to use the representation of a previous input to aid the representation of the later input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJmKbj0xppFu"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typicall looks like this:\n",
        "\n",
        "Input (text) - Tokenize - Embedding - Layers (RNN/dense) - Output (label probability)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDlG_Bq2sFwZ"
      },
      "source": [
        "#Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#x = layers.LSTM(64, return_sequences=True)(x) #when you´re stacking RNN cells together, you need to set return_sequences=True\n",
        "x = layers.LSTM(64, return_sequences=False)(x)\n",
        "#x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsDKK1N4s5xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a06aa3-3f2f-4da9-94fd-8f7ed2bdbf2e"
      },
      "source": [
        "#Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_3 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSRxzUkotdFs"
      },
      "source": [
        "#Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTmaIu07umiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043e78cd-d201-4358-aa57-11ed008e7200"
      },
      "source": [
        "#Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_2_LSTM\")])"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210813-090759\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 24ms/step - loss: 0.2231 - accuracy: 0.9196 - val_loss: 0.5670 - val_accuracy: 0.7756\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.1550 - accuracy: 0.9426 - val_loss: 0.7146 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.1284 - accuracy: 0.9524 - val_loss: 0.7506 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.1026 - accuracy: 0.9594 - val_loss: 0.7594 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.0851 - accuracy: 0.9663 - val_loss: 0.9132 - val_accuracy: 0.7756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpwl3msHvFL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56637992-ca30-4a26-aaa0-a0cac7f62a3a"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.8792320e-03],\n",
              "       [8.2653737e-01],\n",
              "       [9.9949861e-01],\n",
              "       [3.1141406e-02],\n",
              "       [3.3108320e-04],\n",
              "       [9.6556139e-01],\n",
              "       [5.3630626e-01],\n",
              "       [9.9960858e-01],\n",
              "       [9.9934000e-01],\n",
              "       [2.1382971e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGRo_HSzvP3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dcc40cd-fd3c-46bd-d9b1-8e52196835c2"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCwUptn-vhP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f15b08-69b8-4a70-f5c8-7b51c43218c0"
      },
      "source": [
        "#Calculate model 2 results\n",
        "model_2_results = calculate_results(val_labels, model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55905511811024,\n",
              " 'f1': 0.770997050538307,\n",
              " 'precision': 0.7841484675632434,\n",
              " 'recall': 0.7755905511811023}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1wrWsD0vuvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2e03b8-1b63-4b90-9ab0-f278250828ac"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySmxGBSdvxkG"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX9UKeLl2ZO4"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64, return_sequences=False)(x)\n",
        "#x = layers.LSTM(64)(x)\n",
        "#x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO7upDQu3XaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52154d82-1ddf-4853-a28a-c0cf6b242347"
      },
      "source": [
        "#get model summary\n",
        "model_3.summary()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_3 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6CTXbMK3jGK"
      },
      "source": [
        "#Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=\"accuracy\")"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GXMZZKQ4xer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67377381-b711-4dd0-8b08-266243bcd581"
      },
      "source": [
        "#Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_3_GRU\")])"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20210813-090844\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 24ms/step - loss: 0.1598 - accuracy: 0.9385 - val_loss: 0.8298 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0833 - accuracy: 0.9693 - val_loss: 0.8006 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0693 - accuracy: 0.9734 - val_loss: 0.9033 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0610 - accuracy: 0.9740 - val_loss: 1.0746 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0514 - accuracy: 0.9764 - val_loss: 1.1617 - val_accuracy: 0.7743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUrPdgvW5GWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7740d751-9011-485a-9470-f018b2598cdb"
      },
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1937498e-02],\n",
              "       [7.5406992e-01],\n",
              "       [9.9963033e-01],\n",
              "       [1.7922531e-01],\n",
              "       [1.4687696e-04],\n",
              "       [9.9965656e-01],\n",
              "       [7.8835469e-01],\n",
              "       [9.9987900e-01],\n",
              "       [9.9980968e-01],\n",
              "       [9.5342684e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdU4WLfS5REz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67fe3bf4-45ae-43cf-eb2c-773a484a5b88"
      },
      "source": [
        "#Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RBYauIp5kEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f07798e-9b8f-4ad6-c728-9bf67d0d68aa"
      },
      "source": [
        "#Calculate model 3 results\n",
        "model_3_results = calculate_results(val_labels, model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'f1': 0.773426649133647,\n",
              " 'precision': 0.7741317342942483,\n",
              " 'recall': 0.7742782152230971}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "187Ajtvsd45u"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN´s go from left to right (just like you´d read an english sentence) however, a bidirectional RNN goes from right to left as well as from right to left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrwrEgnbdu6P"
      },
      "source": [
        "# Build a bidirectional RNN in tensorflow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNZs6RfnfqX3",
        "outputId": "ed82048b-453e-4851-8314-791950f38068",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_3 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2BSkvZXftxU"
      },
      "source": [
        "#Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bPfn3Plgcr1",
        "outputId": "84afbecb-3a1f-461b-f8b3-0b30c951e756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit the model\n",
        "model_4_history = model_4.fit(train_sentences, \n",
        "                              train_labels, \n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_4_bidirectional\")])"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20210813-090928\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 34ms/step - loss: 0.1036 - accuracy: 0.9704 - val_loss: 1.0226 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0513 - accuracy: 0.9771 - val_loss: 1.3406 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.0445 - accuracy: 0.9794 - val_loss: 1.2593 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.0440 - accuracy: 0.9804 - val_loss: 1.5102 - val_accuracy: 0.7835\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.0373 - accuracy: 0.9818 - val_loss: 1.4781 - val_accuracy: 0.7690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljgz5tvlgv79",
        "outputId": "5a16099b-71dd-46b7-9af5-fa0d5b850399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make predictions\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.1779272e-04],\n",
              "       [7.5630802e-01],\n",
              "       [9.9995089e-01],\n",
              "       [2.6012307e-01],\n",
              "       [5.4305665e-06],\n",
              "       [9.9946493e-01],\n",
              "       [2.8271589e-01],\n",
              "       [9.9998581e-01],\n",
              "       [9.9997747e-01],\n",
              "       [9.9805272e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVhrPTMxhF9_",
        "outputId": "b54d9ddf-a3ea-4abc-ee28-d7647d8b5c5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Convert pred probs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDpOxVSAhOLh",
        "outputId": "6635f607-ad89-4f63-ba95-fa88efa5f14c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#calculate the result of our bidirectional model\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.7669342344352704,\n",
              " 'precision': 0.7706028054440214,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLFjD_OPiN8M"
      },
      "source": [
        "## Convolution Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "We´ve used CNNs for images but images are typically 2D (height x width)... however, out text data is 1D.\n",
        "\n",
        "Previously we´ve used Conv2D for our image data but now we´re going to use Conv1D.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences (in out case, text):\n",
        "\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers (Conv1D + Pooling) -> Outputs (class probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9l9KmL7oDMO"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "For different explanations of parameter see:\n",
        "* CNN explainer (this is for 2D but can relate to 1D)\n",
        "* Difference between same and valid - Google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSH1dvuXhXTh",
        "outputId": "fa46c299-7ead-417e-9826-0fab8e025ecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Test out out embedding layer, Conv1D layer and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) #turn target into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5, #looks at 5 words at a time\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\") # deafult = \"valid\", the output is smaller than the input shape\n",
        "\n",
        "conv_1d_output = conv_1d(embedding_test) #pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPooling1D()\n",
        "max_pool_output = max_pool(conv_1d_output) #get the most important features - features with highest values\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDWvb5ylpM4w"
      },
      "source": [
        "#embedding_test"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2XfNgTrsFyn"
      },
      "source": [
        "#conv_1d_output"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nLOLNaFsIb5"
      },
      "source": [
        "#max_pool_output"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnVHvJoZseXJ"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=5,\n",
        "                  activation=\"relu\",\n",
        "                  padding=\"valid\",\n",
        "                  strides=1)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKQj5uTwtKXP"
      },
      "source": [
        "#Compile Conv1D\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"Adam\", \n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YIvHTsPuWiw",
        "outputId": "82adbcc5-8611-4a64-d84f-864250a109f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_5.summary()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_3 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_6 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3yl7Uf0umet",
        "outputId": "9e784826-5c5c-4520-b164-fd9c24df44f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"Conv1D\")])"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210813-091001\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 20ms/step - loss: 0.1284 - accuracy: 0.9565 - val_loss: 0.8619 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0744 - accuracy: 0.9708 - val_loss: 1.0324 - val_accuracy: 0.7625\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0627 - accuracy: 0.9742 - val_loss: 1.1407 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0569 - accuracy: 0.9768 - val_loss: 1.1460 - val_accuracy: 0.7651\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0514 - accuracy: 0.9778 - val_loss: 1.2308 - val_accuracy: 0.7507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "166yq7jyu1dT",
        "outputId": "b408543d-b40b-465b-f48a-561d1ca00863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make some predictions\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.20458744e-01],\n",
              "       [7.09752560e-01],\n",
              "       [9.99951959e-01],\n",
              "       [6.37307540e-02],\n",
              "       [4.61782612e-08],\n",
              "       [9.95769620e-01],\n",
              "       [9.47468996e-01],\n",
              "       [9.99904633e-01],\n",
              "       [9.99999642e-01],\n",
              "       [8.99997950e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__t4nWWdvFsJ",
        "outputId": "7a4525e7-ea46-437d-978f-2c3e83fb092b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Convert pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5QC3VvJvOhp",
        "outputId": "97396f1f-98fb-4a95-d799-c4d0c5f5440b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluate predictions\n",
        "model_5_results = calculate_results(val_labels,\n",
        "                                    model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.06561679790026,\n",
              " 'f1': 0.7491705324008289,\n",
              " 'precision': 0.7507272180149456,\n",
              " 'recall': 0.7506561679790026}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HubhWYSxa2v"
      },
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Now we´ve build a few of our own models, let´s try and use transfer learning for NLP, specifically using TensorFlow Hub´s pretrained Encoder: https://tfhub.dev/google/universal-sentence-encoder/4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPfoXX5Bx8hh",
        "outputId": "701c666a-35fb-4522-e4d6-a879349bcc3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([\"sample sentence\", \"When you call the universal sentence encoder, it turns it into number\"])\n",
        "embed_samples[0][:50]"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
              "array([-0.03938255,  0.00283756,  0.02243922,  0.0245115 , -0.04985989,\n",
              "        0.05275185,  0.01906133,  0.03593649, -0.04484411,  0.01787181,\n",
              "       -0.03389932, -0.00872529, -0.02777038,  0.09363514, -0.02399772,\n",
              "       -0.08983202, -0.03871281,  0.00450141, -0.02363318, -0.03881208,\n",
              "       -0.01647638,  0.04881011, -0.00920218,  0.05666861, -0.06821936,\n",
              "        0.06926924, -0.01130831, -0.0776007 ,  0.00864499, -0.02895822,\n",
              "        0.00346943,  0.01833375, -0.06229274,  0.02653736, -0.09129825,\n",
              "        0.02586216, -0.00045973,  0.03273476, -0.06651258,  0.03915777,\n",
              "       -0.03467299,  0.0575624 , -0.00661325, -0.01383738, -0.04131497,\n",
              "       -0.02762501,  0.04249629, -0.00791721,  0.04456056, -0.01393928],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msv0GRq6zuD_",
        "outputId": "4606fec3-029b-4a76-9721-00604969de0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embed_samples[0].shape"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafF8_Rj0kdp"
      },
      "source": [
        "# Create a Keras Layers using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], #because input can be of variable length\n",
        "                                        dtype=tf.string, trainable=False, name=\"USE\")"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UbwKMLM0D6K"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "                               sentence_encoder_layer,\n",
        "                               layers.Dense(64, activation=\"relu\"),\n",
        "                               layers.Dense(1, activation=\"sigmoid\")\n",
        "                               \n",
        "], name=\"model_6_USE\")"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kijVGcIQ1tu4"
      },
      "source": [
        "#Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytFP_sX1036",
        "outputId": "d462f451-0e55-43f0-f184-ecaac3e8304e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_6.summary()"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l94Lepyy12dg",
        "outputId": "4c09fa7d-c9b0-4300-8734-ad45704b203d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit the model\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210813-093414\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 24ms/step - loss: 0.5060 - accuracy: 0.7854 - val_loss: 0.4496 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.4154 - accuracy: 0.8139 - val_loss: 0.4410 - val_accuracy: 0.8071\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.4009 - accuracy: 0.8206 - val_loss: 0.4366 - val_accuracy: 0.8110\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.3932 - accuracy: 0.8247 - val_loss: 0.4365 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.3848 - accuracy: 0.8311 - val_loss: 0.4248 - val_accuracy: 0.8189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb1uZqZi2RL5",
        "outputId": "98dd17cd-8a97-4ee4-bafd-dc06f448e03a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17159581],\n",
              "       [0.82918555],\n",
              "       [0.99143267],\n",
              "       [0.21850964],\n",
              "       [0.74741983],\n",
              "       [0.7336558 ],\n",
              "       [0.9840274 ],\n",
              "       [0.98336697],\n",
              "       [0.9511763 ],\n",
              "       [0.10333898]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_k-UhkG2kBu",
        "outputId": "5f2460dd-49fc-455c-8872-8585dcb53ee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPl74x7j2u5C",
        "outputId": "de01acb9-4919-405f-df7d-a1632a593db9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.88976377952756,\n",
              " 'f1': 0.817984880977007,\n",
              " 'precision': 0.8196605460013572,\n",
              " 'recall': 0.8188976377952756}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P18GEfr124iz",
        "outputId": "8bfe1220-1539-4f3f-d63e-90288161fc8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_sentences)"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6851"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8ELPA9V4A6u"
      },
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning helps when you don´t have a large dataset.\n",
        "To see how our model performs on a smaller dataset, let´s replicate model_6 except we´ll train it on 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvNVAmvy3oRb"
      },
      "source": [
        "# Create subsets of 10% of the training data\n",
        "train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "train_labels_10_percent = train_10_percent[\"target\"].to_list()"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Log5M1-h4lDB",
        "outputId": "f8b89adf-8efe-4c13-cdab-f10d85a9f571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(761, 761)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eudKtAry4ykY",
        "outputId": "617a7553-8e9a-4eb6-e2da-82735df969bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Check the number of targets in our subset of data\n",
        "train_10_percent[\"target\"].value_counts()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    413\n",
              "1    348\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT4_lpPd5IWX",
        "outputId": "9e8a5b61-9d96-4e7b-9a88-fbb1ca0f59e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bHZXb-T6JCG"
      },
      "source": [
        "To recreate a model same to a previous model you´ve created you can use the tf.keras.models.clone_model() method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHNMGEn-5Oo4"
      },
      "source": [
        "#Build the model - same as model_6\n",
        "\n",
        "model_7 = tf.keras.models.clone_model(model_6)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrvbvS7k6n1m"
      },
      "source": [
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQlrwnFq6ywB",
        "outputId": "d0091063-c798-41be-f1bb-e244dd527470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_7.summary()"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P8aMOuP62tG",
        "outputId": "bbda9e63-4dff-4167-b430-f97543346d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fit the model\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"tf_hub_sentence_encoder_10_percent\")])"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent/20210813-095335\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 6s 135ms/step - loss: 0.6628 - accuracy: 0.7188 - val_loss: 0.6221 - val_accuracy: 0.7966\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 1s 45ms/step - loss: 0.5886 - accuracy: 0.7858 - val_loss: 0.5429 - val_accuracy: 0.8005\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 1s 43ms/step - loss: 0.5159 - accuracy: 0.7976 - val_loss: 0.4788 - val_accuracy: 0.8058\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.4625 - accuracy: 0.8081 - val_loss: 0.4371 - val_accuracy: 0.8176\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 1s 30ms/step - loss: 0.4285 - accuracy: 0.8160 - val_loss: 0.4085 - val_accuracy: 0.8281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmxSEu8v7l-X",
        "outputId": "b8d742de-b29c-4a05-ba2c-26eab6b5fd06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Make predictions \n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23691262],\n",
              "       [0.8167402 ],\n",
              "       [0.91525126],\n",
              "       [0.33503708],\n",
              "       [0.7688092 ],\n",
              "       [0.8158242 ],\n",
              "       [0.901649  ],\n",
              "       [0.93976486],\n",
              "       [0.8272687 ],\n",
              "       [0.06308784]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW0Rd5vo73GB",
        "outputId": "294cae3e-8c9f-4282-9827-3c41cb61d5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT-pGeom7_x5",
        "outputId": "ad8a919d-dedf-471f-e3f6-12272c0079af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Evaluate predictions\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.80839895013123,\n",
              " 'f1': 0.8272554155579622,\n",
              " 'precision': 0.8288722528604506,\n",
              " 'recall': 0.8280839895013123}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    }
  ]
}